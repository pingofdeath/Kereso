<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
				<meta name="keywords" content="No free lunch in search and optimization,Evolutionary computation,Intelligent design,Specified complexity,William A. Dembski,Fitness function,Intelligent design movement,Candidate solution,Candidate solutions,Coevolution,Croupier" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<title>No free lunch in search and optimization - Wikipedia, the free encyclopedia</title>
		<style type="text/css" media="screen, projection">/*<![CDATA[*/
			@import "/skins-1.5/common/shared.css?97";
			@import "/skins-1.5/monobook/main.css?97";
		/*]]>*/</style>
		<link rel="stylesheet" type="text/css" media="print" href="/skins-1.5/common/commonPrint.css?97" />
		<!--[if lt IE 5.5000]><style type="text/css">@import "/skins-1.5/monobook/IE50Fixes.css?97";</style><![endif]-->
		<!--[if IE 5.5000]><style type="text/css">@import "/skins-1.5/monobook/IE55Fixes.css?97";</style><![endif]-->
		<!--[if IE 6]><style type="text/css">@import "/skins-1.5/monobook/IE60Fixes.css?97";</style><![endif]-->
		<!--[if IE 7]><style type="text/css">@import "/skins-1.5/monobook/IE70Fixes.css?97";</style><![endif]-->
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?97"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->
		
		<script type= "text/javascript">/*<![CDATA[*/
var skin = "monobook";
var stylepath = "/skins-1.5";
var wgArticlePath = "/wiki/$1";
var wgScriptPath = "/w";
var wgScript = "/w/index.php";
var wgServer = "http://en.wikipedia.org";
var wgCanonicalNamespace = "";
var wgCanonicalSpecialPageName = false;
var wgNamespaceNumber = 0;
var wgPageName = "No_free_lunch_in_search_and_optimization";
var wgTitle = "No free lunch in search and optimization";
var wgAction = "view";
var wgRestrictionEdit = [];
var wgRestrictionMove = [];
var wgArticleId = "1297402";
var wgIsArticle = true;
var wgUserName = null;
var wgUserGroups = null;
var wgUserLanguage = "en";
var wgContentLanguage = "en";
var wgBreakFrames = false;
var wgCurRevisionId = "157119063";
/*]]>*/</script>
                
		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?97"><!-- wikibits js --></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
		<style type="text/css">/*<![CDATA[*/
@import "/w/index.php?title=MediaWiki:Common.css&usemsgcache=yes&action=raw&ctype=text/css&smaxage=2678400";
@import "/w/index.php?title=MediaWiki:Monobook.css&usemsgcache=yes&action=raw&ctype=text/css&smaxage=2678400";
@import "/w/index.php?title=-&action=raw&gen=css&maxage=2678400";
/*]]>*/</style>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?97"></script>
	</head>
<body  class="mediawiki ns-0 ltr page-No_free_lunch_in_search_and_optimization">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
				<h1 class="firstHeading">No free lunch in search and optimization</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="dablink">This article is about the computing principle.  For the more general phrase, see <a href="/wiki/TANSTAAFL" title="TANSTAAFL">TANSTAAFL</a>.</div>
<p>In computing, there are circumstances in which the outputs of all procedures solving a particular type of problem are statistically identical. A colorful way of describing such a circumstance, introduced by David H. Wolpert and William G. Macready in connection with the problems of search<sup id="_ref-WM95_0" class="reference"><a href="#_note-WM95" title="">[1]</a></sup> and optimization,<sup id="_ref-WM97_0" class="reference"><a href="#_note-WM97" title="">[2]</a></sup> is to say that there is <a href="/wiki/No_free_lunch" title="No free lunch">no free lunch</a>.</p>
<p>To pursue the "no free lunch" <a href="/wiki/Metaphor" title="Metaphor">metaphor</a>, if procedures are eateries and problems are menu items, then the eateries all charge the same prices, but associate the prices with different items. If one lunches daily at a particular eatery and orders from across the menu, the average cost of lunch does not depend on the eatery. A way to reduce the average cost is to know the menus of various eateries, and to choose an eatery daily to minimize the cost of one's order. That is, when there is no free lunch, superior performance hinges on matching problem solvers to problems.</p>
<p>In formal terms, there is no free lunch when the <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> of problem instances is such that all problem solvers have identically distributed results. In the case of <a href="/wiki/Search" title="Search">search</a>, a problem instance is an <a href="/wiki/Objective_function" title="Objective function">objective function</a>, and a result is a <a href="/wiki/Sequence" title="Sequence">sequence</a> of values obtained in evaluation of <a href="/wiki/Candidate_solutions" title="Candidate solutions">candidate solutions</a> in the <a href="/wiki/Function_domain" title="Function domain">domain</a> of the function. For typical interpretations of results, search is an <a href="/wiki/Optimization_%28mathematics%29" title="Optimization (mathematics)">optimization</a> process. There is no free lunch in search if and only if the distribution of objective functions is invariant under <a href="/wiki/Permutation" title="Permutation">permutation</a> of the space of candidate solutions.<sup id="_ref-Igel_0" class="reference"><a href="#_note-Igel" title="">[3]</a></sup><sup id="_ref-English2004_0" class="reference"><a href="#_note-English2004" title="">[4]</a></sup></p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a></li>
<li class="toclevel-1"><a href="#No_free_lunch_.28NFL.29"><span class="tocnumber">2</span> <span class="toctext">No free lunch (NFL)</span></a></li>
<li class="toclevel-1"><a href="#Example:_Roulette_and_NFL"><span class="tocnumber">3</span> <span class="toctext">Example: Roulette and NFL</span></a></li>
<li class="toclevel-1"><a href="#Formal_synopsis_of_NFL"><span class="tocnumber">4</span> <span class="toctext">Formal synopsis of NFL</span></a></li>
<li class="toclevel-1"><a href="#Original_NFL_theorems"><span class="tocnumber">5</span> <span class="toctext">Original NFL theorems</span></a></li>
<li class="toclevel-1"><a href="#Interpretations_of_NFL_results"><span class="tocnumber">6</span> <span class="toctext">Interpretations of NFL results</span></a></li>
<li class="toclevel-1"><a href="#Coevolutionary_free_lunches"><span class="tocnumber">7</span> <span class="toctext">Coevolutionary free lunches</span></a></li>
<li class="toclevel-1"><a href="#Intelligent_design_and_NFL"><span class="tocnumber">8</span> <span class="toctext">Intelligent design and NFL</span></a></li>
<li class="toclevel-1"><a href="#References_and_notes"><span class="tocnumber">9</span> <span class="toctext">References and notes</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">10</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Overview" id="Overview"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=1" title="Edit section: Overview">edit</a>]</span> <span class="mw-headline">Overview</span></h2>
<p>Some computational problems are solved by searching for good solutions in a space of <a href="/wiki/Candidate_solution" title="Candidate solution">candidate solutions</a>. A description of how to repeatedly select candidate solutions for evaluation is called a <a href="/wiki/Search_algorithm" title="Search algorithm">search algorithm</a>. On a particular problem, different search algorithms may obtain different results, but over all problems, they are indistinguishable. It follows that if an algorithm achieves superior results on some problems, it must pay with inferiority on other problems. In this sense there is <a href="/wiki/No_free_lunch" title="No free lunch">no free lunch</a> for search algorithms.<sup id="_ref-WM95_1" class="reference"><a href="#_note-WM95" title="">[1]</a></sup> Usually search is interpreted as <a href="/wiki/Optimization_%28mathematics%29" title="Optimization (mathematics)">optimization</a>, and this leads to the observation that there is no free lunch for optimizers.<sup id="_ref-WM97_1" class="reference"><a href="#_note-WM97" title="">[2]</a></sup></p>
<p>The body of mathematical results related to "no free lunch" is commonly reduced to a <a href="/wiki/Folk_theorem" title="Folk theorem">folk theorem</a>. "The 'no free lunch' theorem of Wolpert and Macready," as stated by Wolpert and Macready themselves, is that "any two algorithms are equivalent when their performance is averaged across all possible problems."<sup id="_ref-WM-coev_0" class="reference"><a href="#_note-WM-coev" title="">[5]</a></sup> While this follows from two theorems in their seminal work, it is not equivalent to either.<sup id="_ref-WM95_2" class="reference"><a href="#_note-WM95" title="">[1]</a></sup><sup id="_ref-WM97_2" class="reference"><a href="#_note-WM97" title="">[2]</a></sup></p>
<p>"No free lunch" might well have been dubbed <i>conservation of search performance</i> to echo a prior result in the theory of <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>, <a href="/w/index.php?title=Conservation_of_generalization_accuracy&amp;action=edit" class="new" title="Conservation of generalization accuracy">conservation of generalization accuracy</a>.<sup id="_ref-Schaffer94_0" class="reference"><a href="#_note-Schaffer94" title="">[6]</a></sup> The two forms of conservation are closely related.<sup id="_ref-English2000_0" class="reference"><a href="#_note-English2000" title="">[7]</a></sup></p>
<p>The "no free lunch" results indicate that matching algorithms to problems gives higher average performance than does applying a fixed algorithm to all. A false inference, common in folklore and prominent in arguments for <a href="/wiki/Intelligent_design" title="Intelligent design">intelligent design</a>,<sup id="_ref-DembskiNFL_0" class="reference"><a href="#_note-DembskiNFL" title="">[8]</a></sup> is that algorithms do not perform well unless they are customized to problems. To the contrary, every algorithm obtains good solutions rapidly for almost all problems.<sup id="_ref-English2000_1" class="reference"><a href="#_note-English2000" title="">[7]</a></sup> Unfortunately, almost all problems are physically impossible,<sup id="_ref-English2004_1" class="reference"><a href="#_note-English2004" title="">[4]</a></sup> and whether any algorithm is generally effective in the real world is unknown.</p>
<p>The physical impossibility of most problems also limits the practical, though not the theoretical, significance of the original "no free lunch" results. Other work has established a general condition under which there is no free lunch,<sup id="_ref-Igel_1" class="reference"><a href="#_note-Igel" title="">[3]</a></sup><sup id="_ref-English2004_2" class="reference"><a href="#_note-English2004" title="">[4]</a></sup> but while it is physically possible, it does not hold in the world.<sup id="_ref-0" class="reference"><a href="#_note-0" title="">[9]</a></sup> This does not imply, however, that any algorithm exhibits general superiority in a practical sense.<sup id="_ref-English2004_3" class="reference"><a href="#_note-English2004" title="">[4]</a></sup> Whether any actually does is unknown.</p>
<p><a name="No_free_lunch_.28NFL.29" id="No_free_lunch_.28NFL.29"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=2" title="Edit section: No free lunch (NFL)">edit</a>]</span> <span class="mw-headline">No free lunch (NFL)</span></h2>
<p>A "problem" is, more formally, an <a href="/wiki/Objective_function" title="Objective function">objective function</a> that associates <a href="/wiki/Candidate_solution" title="Candidate solution">candidate solutions</a> with goodness values. A <a href="/wiki/Search_algorithm" title="Search algorithm">search algorithm</a> takes an objective function as input and evaluates candidate solutions one-by-one. The output of the algorithm is the <a href="/wiki/Sequence" title="Sequence">sequence</a> of observed goodness values.<sup id="_ref-1" class="reference"><a href="#_note-1" title="">[10]</a></sup><sup id="_ref-English2000_2" class="reference"><a href="#_note-English2000" title="">[7]</a></sup></p>
<p>Wolpert and Macready stipulate that an algorithm never reevaluates a candidate solution, and that algorithm performance is measured on outputs.<sup id="_ref-WM97_3" class="reference"><a href="#_note-WM97" title="">[2]</a></sup> For simplicity, we disallow randomness in algorithms. Under these conditions, when a search algorithm is run on every possible input, it generates each possible output exactly once.<sup id="_ref-English2000_3" class="reference"><a href="#_note-English2000" title="">[7]</a></sup> Because performance is measured on the outputs, the algorithms are indistinguishable in how often they achieve particular levels of performance.</p>
<p>Some measures of performance indicate how well search algorithms do at <a href="/wiki/Optimization_%28mathematics%29" title="Optimization (mathematics)">optimization</a> of the objective function. Indeed, there seems to be no interesting application of search algorithms in the class under consideration but to optimization problems. A common performance measure is the least index of the least value in the output sequence. This is a count of the number of evaluations required to minimize the objective function. For some algorithms, the time required to find the minimum is proportional to the count of evaluations.<sup id="_ref-English2004_4" class="reference"><a href="#_note-English2004" title="">[4]</a></sup></p>
<p>The original no free lunch (NFL) theorems assume that all objective functions are equally likely to be input to search algorithms.<sup id="_ref-WM97_4" class="reference"><a href="#_note-WM97" title="">[2]</a></sup> It has since been established that there is NFL if and only if every objective function is as likely as each of its permutations.<sup id="_ref-Igel_2" class="reference"><a href="#_note-Igel" title="">[3]</a></sup><sup id="_ref-English2004_5" class="reference"><a href="#_note-English2004" title="">[4]</a></sup> (Loosely speaking, a permutation is obtained by shuffling the values associated with candidates.) NFL is physically possible, but in reality objective functions arise despite the impossibility of their permutations, and thus there is not NFL in the world.<sup id="_ref-2" class="reference"><a href="#_note-2" title="">[11]</a></sup></p>
<p>The obvious interpretation of "not NFL" is "free lunch," but this is misleading. NFL is a matter of degree, not an all-or-nothing proposition. If the condition for NFL holds approximately, then all algorithms yield approximately the same results over all objective functions.<sup id="_ref-English2004_6" class="reference"><a href="#_note-English2004" title="">[4]</a></sup> Note also that "not NFL" implies only that algorithms are inequivalent overall by <i>some</i> measure of performance. For a performance measure of interest, algorithms may remain equivalent, or nearly so.<sup id="_ref-English2004_7" class="reference"><a href="#_note-English2004" title="">[4]</a></sup></p>
<p>The reason that almost all objective functions are physically impossible is that they are <a href="/wiki/Kolmogorov_randomness" title="Kolmogorov randomness">incompressible</a>, and do not "fit" in the world.<sup id="_ref-English2000_4" class="reference"><a href="#_note-English2000" title="">[7]</a></sup> Incompressibility equates to an extreme of irregularity and unpredictability. All levels of goodness are equally represented among candidate solutions, and good solutions are scattered all about the space of candidates. A search algorithm will rarely evaluate more than a small fraction of the candidates before locating a very good solution.<sup id="_ref-English2000_5" class="reference"><a href="#_note-English2000" title="">[7]</a></sup></p>
<p><a name="Example:_Roulette_and_NFL" id="Example:_Roulette_and_NFL"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=3" title="Edit section: Example: Roulette and NFL">edit</a>]</span> <span class="mw-headline">Example: Roulette and NFL</span></h2>
<p>If all objective functions are equally likely, then optimizing a randomly-selected objective function is like spinning a roulette wheel repeatedly to optimize the outcome (the number of the pocket the ball lands in).<sup id="_ref-English1996_0" class="reference"><a href="#_note-English1996" title="">[12]</a></sup></p>
<p>Consider a game with one hundred <a href="/wiki/Roulette_wheel" title="Roulette wheel">European roulette wheels</a> numbered from 1 to 100. <a href="/wiki/Croupier" title="Croupier">Croupiers</a> spin the wheels, wait for outcomes, and then cover the wheels with shrouds. The association of wheels with outcomes serves as the objective function <i>f</i>, where <i>f</i>(<i>n</i>) is the outcome at wheel <i>n</i>. The player removes shrouds one at a time, attempting to locate the wheel <i>n</i> maximizing <i>f</i>(<i>n</i>). Performance is the number of shrouds removed to find the maximum.</p>
<p>Now consider that there is no need to spin the wheels in advance and hide the outcomes. The player may simply visit wheel <i>n</i> and ask the croupier to spin it to determine <i>f</i>(<i>n</i>). Whether the wheel is spun before or after the player arrives has no impact on the outcome.</p>
<p>There is also no need for more than one wheel. Spinning one wheel 100 times is equivalent to spinning 100 wheels once. A croupier gives the player tickets numbered from 1 to 100. Prior to each spin of a single wheel, the player hands the croupier ticket <i>n</i>, and the outcome of the spin determines <i>f</i>(<i>n</i>). Performance is now the number of spins required to find the maximum.</p>
<p>The tickets have no impact on the outcomes. That is, the sequence of observed values does not depend on the search algorithm (strategy for selecting tickets). All objective functions are equally likely to be generated, and all sequences of values are equally likely to be observed. Thus performance does not depend on the algorithm, and there is no free lunch for players of the optimization game.</p>
<p><a name="Formal_synopsis_of_NFL" id="Formal_synopsis_of_NFL"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=4" title="Edit section: Formal synopsis of NFL">edit</a>]</span> <span class="mw-headline">Formal synopsis of NFL</span></h2>
<p>The set of all <a href="/wiki/Objective_function" title="Objective function">objective functions</a> is <span class="texhtml"><i>Y</i><sup><i>X</i></sup></span>, where <span class="texhtml"><i>X</i></span> is a finite <a href="/wiki/Solution_space" title="Solution space">solution space</a> and <span class="texhtml"><i>Y</i></span> is a finite <a href="/wiki/Poset" title="Poset">poset</a>. The set of all <a href="/wiki/Permutation" title="Permutation">permutations</a> of <i>X</i> is <i>J</i>. Random variable <i>F</i> is distributed on <span class="texhtml"><i>Y</i><sup><i>X</i></sup></span>. For all <i>j</i> in <i>J</i>, <i>F</i> o <i>j</i> is a random variable distributed on <span class="texhtml"><i>Y</i><sup><i>X</i></sup></span>, with Pr{<i>F</i> o <i>j</i> = <i>f</i>} = Pr{<i>F</i> = <i>f</i> o <i>j</i><sup>–1</sup>} for all <i>f</i> in <span class="texhtml"><i>Y</i><sup><i>X</i></sup></span>. A <i>search algorithm</i> is functionally equivalent to</p>
<p><br /></p>
<dl>
<dd><b>Input</b>: <i>f</i> ∈ <i>Y<sup>X</sup></i></dd>
<dd><b>Output</b>: <i>y</i> ∈ <i>Y</i><sup>|<i>X</i>|</sup>
<ol>
<li><i>S</i> ← <i>X</i></li>
<li><i>x</i> ← ε</li>
<li><i>y</i> ← ε</li>
<li>Do |<i>X</i>| times:
<ol>
<li><i>a</i> ← NextToEvaluate(<i>S</i>, <i>x</i>, <i>y</i>)</li>
<li><i>b</i> ← <i>f</i>(<i>a</i>)</li>
<li><i>S</i> ← <i>S</i> \ {<i>a</i>}</li>
<li><i>x</i> ← <i>xa</i></li>
<li><i>y</i> ← <i>yb</i></li>
</ol>
</li>
<li>Return <i>y</i></li>
</ol>
</dd>
</dl>
<p><br />
for any deterministic implementation of <i>NextToEvaluate</i> that returns an element of <i>S</i>, the set of unevaluated candidate solutions, without evaluating any element of <i>S</i>. The sequences of evaluated candidates and corresponding values are stored in <i>x</i> and <i>y</i>, respectively.</p>
<p>Let <i>a</i>(<i>f</i>) denote the output of search algorithm <i>a</i> on input <i>f</i>. If <i>a</i>(<i>F</i>) and <i>b</i>(<i>F</i>) are identically distributed for all search algorithms <i>a</i> and <i>b</i>, then <i>F</i> has an <i>NFL distribution</i>. This condition holds if and only if <i>F</i> and <i>F</i> o <i>j</i> are identically distributed for all <i>j</i> in <i>J</i>.<sup id="_ref-English2004_8" class="reference"><a href="#_note-English2004" title="">[4]</a></sup><sup id="_ref-Igel_3" class="reference"><a href="#_note-Igel" title="">[3]</a></sup> In other words, there is no free lunch for search algorithms if and only if the distribution of objective functions is invariant under permutation of the solution space.</p>
<p>Let <i>Φ</i> be any performance measure on <i>Y</i><sup>|<i>X</i>|</sup>. If <i>Φ</i>(<i>a</i>(<i>F</i>)) and <i>Φ</i>(<i>b</i>(<i>F</i>)) are identically distributed for all search algorithms <i>a</i> and <i>b</i>, then <i>F</i> has a <i>Φ-NFL distribution</i>. Every NFL distribution is a <i>Φ</i>-NFL distribution for all performance measures <i>Φ</i>. To see this, suppose that <i>F</i> has an NFL distribution. Then identically distributed <i>a</i>(<i>F</i>) and <i>b</i>(<i>F</i>) imply identically distributed <i>Φ</i>(<i>a</i>(<i>F</i>)) and <i>Φ</i>(<i>b</i>(<i>F</i>)) for all search algorithms <i>a</i> and <i>b</i> and for all single-valued performance measures <i>Φ</i>.</p>
<p><a name="Original_NFL_theorems" id="Original_NFL_theorems"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=5" title="Edit section: Original NFL theorems">edit</a>]</span> <span class="mw-headline">Original NFL theorems</span></h2>
<p>In the introduction to their first publication on NFL, Wolpert and Macready write</p>
<p><br /></p>
<dl>
<dd>Roughly speaking, we show that for both static and time-dependent optimization problems, <i>the average performance of any pair of algorithms across all possible problems is identical</i>.<sup id="_ref-WM97_5" class="reference"><a href="#_note-WM97" title="">[2]</a></sup></dd>
</dl>
<p><br />
Emphasis is added here to highlight the folkloric NFL theorem. There are actually two principal NFL theorems in the article, the first regarding objective functions that do not change while search is in progress, and the second regarding objective functions that may change.</p>
<p><br /></p>
<dl>
<dd><i>Theorem 1</i>: For any pair of algorithms <i>a</i><sub>1</sub> and <i>a</i><sub>2</sub></dd>
</dl>
<dl>
<dd>
<dl>
<dd><img class="tex" alt="\sum_f P(h_m^y | f, m, a_1) = \sum_f P(h_m^y | f, m, a_2)." src="http://upload.wikimedia.org/math/f/2/0/f2024c12c1a08b3db90eb4afb3e9605a.png" /></dd>
</dl>
</dd>
</dl>
<p><br />
Assuming deterministic algorithms, a reasonably accurate paraphrase is that the number of objective functions <i>f</i> for which an arbitrary <a href="/wiki/Multiset" title="Multiset">multiset</a> <i>h<sup>y</sup></i> of values is observed after evaluation of <i>m</i> candidate solutions is identical for all algorithms. This implies the folkloric NFL theorem, and considerably more. Theorem 2 establishes a "more subtle" NFL result for time-varying objective functions.<sup id="_ref-WM97_6" class="reference"><a href="#_note-WM97" title="">[2]</a></sup></p>
<p><a name="Interpretations_of_NFL_results" id="Interpretations_of_NFL_results"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=6" title="Edit section: Interpretations of NFL results">edit</a>]</span> <span class="mw-headline">Interpretations of NFL results</span></h2>
<p>A conventional, but not entirely accurate, interpretation of the NFL results is that "a general-purpose universal optimization strategy is theoretically impossible, and the only way one strategy can outperform another is if it is specialized to the specific problem under consideration"<sup id="_ref-3" class="reference"><a href="#_note-3" title="">[13]</a></sup>. Several comments are in order:</p>
<dl>
<dd><i>A general-purpose almost-universal optimizer exists theoretically.</i> Each search algorithm performs well on almost all objective functions.<sup id="_ref-English2000_6" class="reference"><a href="#_note-English2000" title="">[7]</a></sup></dd>
</dl>
<dl>
<dd><i>An algorithm may outperform another on a problem when neither is specialized to the problem.</i> It may be that both algorithms are among the worst for the problem. Wolpert and Macready have developed a measure of the degree of "match" between an algorithm and a problem.<sup id="_ref-WM97_7" class="reference"><a href="#_note-WM97" title="">[2]</a></sup> To say that one algorithm matches a problem better than another is not to say that either is specialized to the problem.</dd>
</dl>
<dl>
<dd><i>In practice, some algorithms reevaluate candidate solutions.</i> The superiority of an algorithm that never reevaluates candidates over another that does on a particular problem may have nothing to do with specialization to the problem.</dd>
</dl>
<dl>
<dd><i>For almost all objective functions, specialization is essentially accidental.</i> Incompressible, or <a href="/wiki/Kolmogorov_randomness" title="Kolmogorov randomness">Kolmogorov random</a>, objective functions have no regularity for an algorithm to exploit. Given an incompressible objective function, there is no basis for choosing one algorithm over another. If a chosen algorithm performs better than most, the result is happenstance.<sup id="_ref-English2000_7" class="reference"><a href="#_note-English2000" title="">[7]</a></sup></dd>
</dl>
<p>In practice, only highly-compressible (far from random) objective functions fit in the storage of computers, and it is not the case that each algorithm performs well on almost all compressible functions. There is generally a performance advantage in incorporating prior knowledge of the problem into the algorithm. While the NFL results constitute, in a strict sense, <a href="/wiki/Full_employment_theorem" title="Full employment theorem">full employment theorems</a> for optimization professionals, it is important not to take the term literally. For one thing, humans often have little prior knowledge to work with. For another, incorporating prior knowledge does not give much of a performance gain on some problems. Finally, human time is very expensive relative to computer time. There are many cases in which a company would choose to optimize a function slowly with an unmodified computer program rather than rapidly with a human-modified program.</p>
<p>The NFL results do not indicate that it is futile to take "pot shots" at problems with unspecialized algorithms. No one has determined the fraction of practical problems for which an algorithm yields good results rapidly. And there is a practical free lunch, not at all in conflict with theory. Running an implementation of an algorithm on a computer costs very little relative to the cost of human time and the benefit of a good solution. If an algorithm succeeds in finding a satisfactory solution in an acceptable amount of time, a small investment has yielded a big payoff. If the algorithm fails, then little is lost.</p>
<p><a name="Coevolutionary_free_lunches" id="Coevolutionary_free_lunches"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=7" title="Edit section: Coevolutionary free lunches">edit</a>]</span> <span class="mw-headline">Coevolutionary free lunches</span></h2>
<p>Wolpert and Macready have proved that there are free lunches in <a href="/wiki/Coevolution" title="Coevolution">coevolutionary</a> optimization.<sup id="_ref-WM-coev_1" class="reference"><a href="#_note-WM-coev" title="">[5]</a></sup> Their analysis "covers 'self-play' problems. In these problems, the set of players work together to produce a champion, who then engages one or more antagonists in a subsequent multiplayer game."<sup id="_ref-WM-coev_2" class="reference"><a href="#_note-WM-coev" title="">[5]</a></sup> That is, the objective is to obtain a good player, but without an objective function. The goodness of each player (candidate solution) is assessed by observing how well it plays against others. An algorithm attempts to use players and their quality of play to obtain better players. The player deemed best of all by the algorithm is the champion. Wolpert and Macready have demonstrated that some coevolutionary algorithms are generally superior to other algorithms in quality of champions obtained. Generating a champion through self-play is of interest in <a href="/wiki/Evolutionary_computation" title="Evolutionary computation">evolutionary computation</a> and <a href="/wiki/Game_theory" title="Game theory">game theory</a>. The results are inapplicable to coevolution of biological species, which does not yield champions.<sup id="_ref-WM-coev_3" class="reference"><a href="#_note-WM-coev" title="">[5]</a></sup></p>
<p><a name="Intelligent_design_and_NFL" id="Intelligent_design_and_NFL"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=8" title="Edit section: Intelligent design and NFL">edit</a>]</span> <span class="mw-headline">Intelligent design and NFL</span></h2>
<p>The central thesis of <a href="/wiki/Intelligent_design" title="Intelligent design">intelligent design</a> is that only intelligent processes can give rise to natural entities with high <a href="/wiki/Specified_complexity" title="Specified complexity">specified complexity</a>. This is similar to the notion that only algorithms incorporating prior knowledge of the problem can achieve high performance. Intelligent design advocate <a href="/wiki/William_A._Dembski" title="William A. Dembski">William A. Dembski</a> indeed makes various references to the NFL theorems in <i>No Free Lunch: Why Specified Complexity Cannot be Purchased Without Intelligence</i>, indicating that effective optimization requires intelligently designed algorithms.<sup id="_ref-DembskiNFL_1" class="reference"><a href="#_note-DembskiNFL" title="">[8]</a></sup> But, as emphasized above, algorithms are almost universally effective in theory, and no one has established how commonly they are effective in practice.</p>
<p>The primary objective of the <a href="/wiki/Intelligent_design_movement" title="Intelligent design movement">intelligent design movement</a> is to counter mainstream evolutionary theory. Biological evolution is often regarded as optimization, and <a href="/wiki/Evolutionary_computation" title="Evolutionary computation">evolutionary computation</a>, which mimics biological evolution, also commonly takes the form of optimization. A large body of research in evolutionary computation suggests that algorithms regularly yield solutions with high specified complexity. Dembski claims that experimenters, as intelligent agents, "smuggle" specified complexity into their programs.<sup id="_ref-DembskiNFL_2" class="reference"><a href="#_note-DembskiNFL" title="">[8]</a></sup> In other words, only algorithms imbued with prior knowledge of the problems would have succeeded.</p>
<p>Notions similar to those associated with Dembski appear at the <a href="http://cayman.globat.com/~trademarksnet.com/Research/EILab/" class="external text" title="http://cayman.globat.com/~trademarksnet.com/Research/EILab/" rel="nofollow">web site</a> of the Evolutionary Informatics Laboratory founded by Distinguished Engineering Professor <a href="/w/index.php?title=Robert_J._Marks_II&amp;action=edit" class="new" title="Robert J. Marks II">Robert J. Marks II</a> of Baylor University. "The principal theme of the lab’s research is teasing apart the respective roles of internally generated and externally applied information in the performance of evolutionary systems." The site provides access to unpublished scholarly papers of Dembski and Marks. The papers make no reference to specified complexity, but emphasize <a href="http://cayman.globat.com/~trademarksnet.com/Research/EILab/Publications/CostOfSuccess.html" class="external text" title="http://cayman.globat.com/~trademarksnet.com/Research/EILab/Publications/CostOfSuccess.html" rel="nofollow">three related types of information</a>:</p>
<blockquote>
<p>Three measures to characterize the information required for successful search are (1) endogenous information, which measures the difficulty of finding a target using random search; (2) exogenous information, which measures the difficulty that remains in finding a target once a search takes advantage of problem-specific information; and (3) active information, which, as the difference between endogenous and exogenous information, measures the contribution of problem-specific information for successfully finding a target.</p>
</blockquote>
<p>This is directly related to NFL, whatever the relationship to intelligent design.</p>
<p>There is some inconsistency in the literature as to whether the NFL results apply to biological evolution. English wrote in 1996,<sup id="_ref-English1996_1" class="reference"><a href="#_note-English1996" title="">[12]</a></sup> and Wolpert concurred in 2002,<sup id="_ref-jello_0" class="reference"><a href="#_note-jello" title="">[14]</a></sup> that in biological evolution the evaluation of "candidate solutions" modifies objective functions (known as <a href="/wiki/Fitness_function" title="Fitness function">fitness functions</a> in this context). There is not an NFL theorem that covers such coupling of search and objective functions. Yet in 2005 Wolpert and Macready stated, without explanation, that their original NFL theorems were applicable to biological evolution.<sup id="_ref-WM-coev_4" class="reference"><a href="#_note-WM-coev" title="">[5]</a></sup></p>
<p><a name="References_and_notes" id="References_and_notes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=9" title="Edit section: References and notes">edit</a>]</span> <span class="mw-headline">References and notes</span></h2>
<div class="references-small">
<ol class="references">
<li id="_note-WM95">^ <a href="#_ref-WM95_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-WM95_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-WM95_2" title=""><sup><i><b>c</b></i></sup></a> Wolpert, D.H., Macready, W.G. (1995), No Free Lunch Theorems for Search, Technical Report SFI-TR-95-02-010 (Santa Fe Institute).</li>
<li id="_note-WM97">^ <a href="#_ref-WM97_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-WM97_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-WM97_2" title=""><sup><i><b>c</b></i></sup></a> <a href="#_ref-WM97_3" title=""><sup><i><b>d</b></i></sup></a> <a href="#_ref-WM97_4" title=""><sup><i><b>e</b></i></sup></a> <a href="#_ref-WM97_5" title=""><sup><i><b>f</b></i></sup></a> <a href="#_ref-WM97_6" title=""><sup><i><b>g</b></i></sup></a> <a href="#_ref-WM97_7" title=""><sup><i><b>h</b></i></sup></a> Wolpert, D.H., Macready, W.G. (1997), "No Free Lunch Theorems for Optimization," <i>IEEE Transactions on Evolutionary Computation</i> <b>1</b>, 67. <a href="http://ic.arc.nasa.gov/people/dhw/papers/78.pdf" class="external free" title="http://ic.arc.nasa.gov/people/dhw/papers/78.pdf" rel="nofollow">http://ic.arc.nasa.gov/people/dhw/papers/78.pdf</a></li>
<li id="_note-Igel">^ <a href="#_ref-Igel_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-Igel_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-Igel_2" title=""><sup><i><b>c</b></i></sup></a> <a href="#_ref-Igel_3" title=""><sup><i><b>d</b></i></sup></a> Igel, C., and Toussaint, M. (2004) "A No-Free-Lunch Theorem for Non-Uniform Distributions of Target Functions," <i>Journal of Mathematical Modelling and Algorithms</i> <b>3</b>, pp. 313–322.</li>
<li id="_note-English2004">^ <a href="#_ref-English2004_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-English2004_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-English2004_2" title=""><sup><i><b>c</b></i></sup></a> <a href="#_ref-English2004_3" title=""><sup><i><b>d</b></i></sup></a> <a href="#_ref-English2004_4" title=""><sup><i><b>e</b></i></sup></a> <a href="#_ref-English2004_5" title=""><sup><i><b>f</b></i></sup></a> <a href="#_ref-English2004_6" title=""><sup><i><b>g</b></i></sup></a> <a href="#_ref-English2004_7" title=""><sup><i><b>h</b></i></sup></a> <a href="#_ref-English2004_8" title=""><sup><i><b>i</b></i></sup></a> English, T. (2004) No More Lunch: Analysis of Sequential Search, <i>Proceedings of the 2004 IEEE Congress on Evolutionary Computation</i>, pp. 227-234. <a href="http://BoundedTheoretics.com/CEC04.pdf" class="external free" title="http://BoundedTheoretics.com/CEC04.pdf" rel="nofollow">http://BoundedTheoretics.com/CEC04.pdf</a></li>
<li id="_note-WM-coev">^ <a href="#_ref-WM-coev_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-WM-coev_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-WM-coev_2" title=""><sup><i><b>c</b></i></sup></a> <a href="#_ref-WM-coev_3" title=""><sup><i><b>d</b></i></sup></a> <a href="#_ref-WM-coev_4" title=""><sup><i><b>e</b></i></sup></a> Wolpert, D.H., and Macready, W.G. (2005) "Coevolutionary free lunches," <i>IEEE Transactions on Evolutionary Computation</i>, 9(6): 721-735</li>
<li id="_note-Schaffer94"><b><a href="#_ref-Schaffer94_0" title="">^</a></b> Schaffer, Cullen (1994), "A conservation law for generalization performance," <i>International Conference on Machine Learning,</i> H. Willian and W. Cohen, Editors. San Francisco: Morgan Kaufmann, pp.295-265.</li>
<li id="_note-English2000">^ <a href="#_ref-English2000_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-English2000_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-English2000_2" title=""><sup><i><b>c</b></i></sup></a> <a href="#_ref-English2000_3" title=""><sup><i><b>d</b></i></sup></a> <a href="#_ref-English2000_4" title=""><sup><i><b>e</b></i></sup></a> <a href="#_ref-English2000_5" title=""><sup><i><b>f</b></i></sup></a> <a href="#_ref-English2000_6" title=""><sup><i><b>g</b></i></sup></a> <a href="#_ref-English2000_7" title=""><sup><i><b>h</b></i></sup></a> English, T. M. 2000. "Optimization Is Easy and Learning Is Hard in the Typical Function," <i>Proceedings of the 2000 Congress on Evolutionary Computation: CEC00</i>, pp. 924-931. <a href="http://www.BoundedTheoretics.com/cec2000.pdf" class="external free" title="http://www.BoundedTheoretics.com/cec2000.pdf" rel="nofollow">http://www.BoundedTheoretics.com/cec2000.pdf</a></li>
<li id="_note-DembskiNFL">^ <a href="#_ref-DembskiNFL_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-DembskiNFL_1" title=""><sup><i><b>b</b></i></sup></a> <a href="#_ref-DembskiNFL_2" title=""><sup><i><b>c</b></i></sup></a> Dembski, W. A. (2002) <i>No Free Lunch</i>, Rowman &amp; Littlefield</li>
<li id="_note-0"><b><a href="#_ref-0" title="">^</a></b> This follows immediately from English's discussion of Kolmogorov complexity of permutations of members of blocks of functions.&lt;ref&gt;&lt;/ref&gt;.</li>
<li id="_note-1"><b><a href="#_ref-1" title="">^</a></b> A search algorithm also outputs the sequence of candidate solutions evaluated, but that output is unused in this article.</li>
<li id="_note-2"><b><a href="#_ref-2" title="">^</a></b> Let <i>f</i> be the function that for all integers <i>n</i> ranging from 1 to a <a href="/wiki/Googolplex" title="Googolplex">googolplex</a> has the value <i>f</i>(<i>n</i>) = <i>n</i>. Although a description of <i>f</i> just occurred in the world, almost all of its permutations require many more bits to describe than there are bits of information in the universe (est. 10<sup>90</sup> by <a href="/wiki/Seth_Lloyd" title="Seth Lloyd">Seth Lloyd</a>).</li>
<li id="_note-English1996">^ <a href="#_ref-English1996_0" title=""><sup><i><b>a</b></i></sup></a> <a href="#_ref-English1996_1" title=""><sup><i><b>b</b></i></sup></a> English, T. M. 1996. "Evaluation of Evolutionary and Genetic Optimizers: No Free Lunch," in L. J. Fogel, P. J. Angeline, T. Bäck (Eds.): <i>Evolutionary Programming V: Proceedings of the Fifth Annual Conference on Evolutionary Programming,</i> pp. 163-169. <a href="http://www.BoundedTheoretics.com/EP96.pdf" class="external free" title="http://www.BoundedTheoretics.com/EP96.pdf" rel="nofollow">http://www.BoundedTheoretics.com/EP96.pdf</a></li>
<li id="_note-3"><b><a href="#_ref-3" title="">^</a></b> Ho, Y.C., Pepyne, D.L. (2002), "Simple Explanation of the No-Free-Lunch Theorem and Its Implications," <i>Journal of Optimization Theory and Applications</i> <b>115</b>, 549.</li>
<li id="_note-jello"><b><a href="#_ref-jello_0" title="">^</a></b> Wolpert, D. (2002) "William Dembski's treatment of the No Free Lunch theorems is written in jello," <a href="http://www.talkreason.org/articles/jello.cfm" class="external free" title="http://www.talkreason.org/articles/jello.cfm" rel="nofollow">http://www.talkreason.org/articles/jello.cfm</a>.</li>
</ol>
</div>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=10" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="/wiki/Inductive_bias" title="Inductive bias">Inductive bias</a></li>
<li><a href="/wiki/Occam%27s_razor" title="Occam's razor">Occam's razor</a></li>
<li><a href="/wiki/Simplicity" title="Simplicity">Simplicity</a></li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit&amp;section=11" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://www.cs.uwyo.edu/~wspears/yin-yang.html" class="external text" title="http://www.cs.uwyo.edu/~wspears/yin-yang.html" rel="nofollow">"Yin-Yang: No-Free-Lunch Theorems for Search"</a></li>
<li><a href="http://www.no-free-lunch.org" class="external free" title="http://www.no-free-lunch.org" rel="nofollow">http://www.no-free-lunch.org</a></li>
</ul>

<!-- 
Pre-expand include size: 2194 bytes
Post-expand include size: 1372 bytes
Template argument size: 369 bytes
Maximum: 2048000 bytes
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1297402-0!1!0!default!!en!2 and timestamp 20070911092143 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization">http://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization</a>"</div>
			<div id="catlinks"><p class='catlinks'><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>: <span dir='ltr'><a href="/wiki/Category:Optimization" title="Category:Optimization">Optimization</a></span> | <span dir='ltr'><a href="/wiki/Category:Mathematical_theorems" title="Category:Mathematical theorems">Mathematical theorems</a></span></p></div>			<!-- end content -->
			<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
					 <li id="ca-nstab-main" class="selected"><a href="/wiki/No_free_lunch_in_search_and_optimization" title="View the content page [c]" accesskey="c">Article</a></li>
					 <li id="ca-talk"><a href="/wiki/Talk:No_free_lunch_in_search_and_optimization" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
					 <li id="ca-edit"><a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=edit" title="You can edit this page. Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
					 <li id="ca-history"><a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>
				</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:Userlogin&amp;returnto=No_free_lunch_in_search_and_optimization" title="You are encouraged to log in, it is not mandatory however. [o]" accesskey="o">Sign in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(/images/wiki-en.png);" href="/wiki/Main_Page" title="Visit the Main Page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-Main-page"><a href="/wiki/Main_Page">Main page</a></li>
				<li id="n-Contents"><a href="/wiki/Wikipedia:Contents">Contents</a></li>
				<li id="n-Featured-content"><a href="/wiki/Wikipedia:Featured_content">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random page [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
		<div class='portlet' id='p-interaction'>
		<h5>interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-About-Wikipedia"><a href="/wiki/Wikipedia:About">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_Portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:Recentchanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
		<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/wiki/Special:Search" id="searchform"><div>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" />
			</div></form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:Whatlinkshere/No_free_lunch_in_search_and_optimization" title="List of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:Recentchangeslinked/No_free_lunch_in_search_and_optimization" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload images or media files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:Specialpages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=No_free_lunch_in_search_and_optimization&amp;oldid=157119063" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=No_free_lunch_in_search_and_optimization&amp;id=157119063">Cite this article</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>In other languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/No-Free-Lunch-Theoreme">Deutsch</a></li>
				<li class="interwiki-gl"><a href="http://gl.wikipedia.org/wiki/Teorema_de_non-existe-o-xantar-de-balde">Galego</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E3%83%8E%E3%83%BC%E3%83%95%E3%83%AA%E3%83%BC%E3%83%A9%E3%83%B3%E3%83%81%E5%AE%9A%E7%90%86">日本語</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
				<li id="lastmod"> This page was last modified 06:26, 16 August 2007.</li>
				<li id="copyright">All text is available under the terms of the <a class='internal' href="/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a U.S. registered <a class='internal' href="/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
				<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
				<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
				<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
		
	
		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
</div>
<!-- Served by srv166 in 0.095 secs. --></body></html>
